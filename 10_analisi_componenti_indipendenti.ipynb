{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riferimenti bibliografici:\n",
    "\n",
    "* Hyvarinen, A. &  Oja, E. (2012), [Independent Component Analysis: Algorithms and Applications](https://www.cs.helsinki.fi/u/ahyvarin/papers/NN00new.pdf).\n",
    "* van der Maaten L., J., P. & Hinton G., E. (2008) [Visualizing Data using t-SNE](http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi delle componenti indipendenti (ICA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Problema del cocktail party](#cocktail)<br />\n",
    "    1.1 [Simulare i dati](#simulare)<br />\n",
    "    1.2 [Utilizzare ICA per ottenere i segnali originali](#ica)<br />\n",
    "2. [Statlog (Landsat Satellite) Data Set](#landsat)<br />\n",
    "    2.1 [Descrizione e lettura del data set](#descrizione)<br />\n",
    "    2.2 [Analisi esplorativa](#esplorativa)<br />\n",
    "3. [PCA, ICA e t-SNE a confronto](#confronto)<br />\n",
    "4. [Ridurre la dimensionalità come parte di una pipeline di classificazione](#pipeline)<br />\n",
    "    4.1 [Creare una baseline](#baseline)<br />\n",
    "    4.2 [Scegliere in numero di componenti principali](#scegliere_principali)<br />\n",
    "    4.3 [Scegliere in numero di componenti indipendenti](#scegliere_indipendenti)<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problema del cocktail party <a id=cocktail> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Simulare i dati <a id=simulare> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.datasets import CocktailParty\n",
    "\n",
    "print(inspect.getsource(CocktailParty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(\n",
    "    [[0.5, 0.5], \n",
    "     [0.2, 0.8]]\n",
    ")\n",
    "\n",
    "cp = CocktailParty(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, 100, 1000)\n",
    "S = np.c_[cp.s1(t), cp.s2(t)]\n",
    "X = np.c_[cp.x1(t), cp.x2(t)]\n",
    "\n",
    "print(\"Dimensioni di S: {} X {}\".format(*S.shape))\n",
    "print(\"Dimensioni di X: {} X {}\".format(*X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.grafici import grafico_cocktail_party\n",
    "\n",
    "print(inspect.getsource(grafico_cocktail_party))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "grafico_cocktail_party(t, S, X)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Utilizzare ICA per ottenere i segnali originali <a id=ica> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(whiten=True, random_state=42)\n",
    "\n",
    "S_hat = ica.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "grafico_cocktail_party(t, S, X, S_hat)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Elencare tutte le differenze tra segnali veri e stimati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.preprocessamento import Sbiancare\n",
    "\n",
    "\n",
    "print(inspect.getsource(Sbiancare))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "1. Completare il metodo `inverse_transform()` della classe `Sbiancare` definita in `msbd/preprocessamento/sbiancare.py`;\n",
    "2. Verificare il corretto funzionamento del metodo appena definito.\n",
    "\n",
    "> Suggerimento: usare il fatto che la matrice $\\mathbf{E}$ è una matrice [unitaria](https://it.wikipedia.org/wiki/Matrice_unitaria)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "1. Definire una pipeline `ica_pipe` con al primo step `Sbiancare()` e al secondo step `FastICA(whiten=False)`;\n",
    "2. Ottenere `S_hat`come `S_hat = ica_pipe.fit_transform(X)`;\n",
    "3. Fare nuovamente il grafico *cocktail party* utilizzando la stima di $\\mathbf{S}$ ottenuta al passo precedente;\n",
    "4. Commentare i risultati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. [Statlog (Landsat Satellite) Data Set](https://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite)) <a id=landsat> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Descrizione e lettura del data set <a id=descrizione> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Information:\n",
    "\n",
    "The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number. \n",
    "\n",
    "The Landsat satellite data is one of the many sources of information available for a scene. The interpretation of a scene by integrating spatial data of diverse types and resolutions including multispectral and radar data, maps indicating topography, land use etc. is expected to assume significant importance with the onset of an era characterised by integrative approaches to remote sensing (for example, NASA's Earth Observing System commencing this decade). Existing statistical methods are ill-equipped for handling such diverse data types. Note that this is not true for Landsat MSS data considered in isolation (as in this sample database). This data satisfies the important requirements of being numerical and at a single resolution, and standard maximum-likelihood classification performs very well. Consequently, for this data, it should be interesting to compare the performance of other methods against the statistical approach. \n",
    "\n",
    "One frame of Landsat MSS imagery consists of four digital images of the same scene in different spectral bands. Two of these are in the visible region (corresponding approximately to green and red regions of the visible spectrum) and two are in the (near) infra-red. Each pixel is a 8-bit binary word, with 0 corresponding to black and 255 to white. The spatial resolution of a pixel is about 80m x 80m. Each image contains 2340 x 3380 such pixels. \n",
    "\n",
    "The database is a (tiny) sub-area of a scene, consisting of 82 x 100 pixels. Each line of data corresponds to a 3x3 square neighbourhood of pixels completely contained within the 82x100 sub-area. Each line contains the pixel values in the four spectral bands (converted to ASCII) of each of the 9 pixels in the 3x3 neighbourhood and a number indicating the classification label of the central pixel. The number is a code for the following classes: \n",
    "\n",
    "#### Number: Class\n",
    "* 1:  red soil \n",
    "* 2:  cotton crop \n",
    "* 3:  grey soil \n",
    "* 4:  damp grey soil \n",
    "* 5:  soil with vegetation stubble \n",
    "* 6:  mixture class (all types present) \n",
    "* 7:  very damp grey soil \n",
    "\n",
    "NB. There are no examples with class 6 in this dataset. \n",
    "\n",
    "The data is given in random order and certain lines of data have been removed so you cannot reconstruct the original image from this dataset. \n",
    "\n",
    "In each line of data the four spectral values for the top-left pixel are given first followed by the four spectral values for the top-middle pixel and then those for the top-right pixel, and so on with the pixels read out in sequence left-to-right and top-to-bottom. Thus, the four spectral values for the central pixel are given by attributes 17,18,19 and 20. If you like you can use only these four attributes, while ignoring the others. This avoids the problem which arises when a 3x3 neighbourhood straddles a boundary. \n",
    "\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "The attributes are numerical, in the range 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CANALI = [\"R\", \"G\", \"B\", \"A\"]\n",
    "CLASSI = [\n",
    "    \"red soil\", \n",
    "    \"cotton crop\", \n",
    "    \"grey soil\", \n",
    "    \"damp grey soil\", \n",
    "    \"soil with vegetation stubble\",\n",
    "    \"very damp grey soil\",\n",
    "]\n",
    "NUMERO_CLASSE = dict(zip([1, 2, 3, 4, 5, 7], CLASSI))\n",
    "NOMI = [\"Pixel{}_{}\".format(i, c) for i in range(9) for c in CANALI] + [\"Classe\"]\n",
    "\n",
    "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn\"\n",
    "\n",
    "dati = pd.read_table(URL, sep=\" \", names=NOMI)\n",
    "print(\"Dimensioni: {} X {}\".format(*dati.shape))\n",
    "dati.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(dati.iloc[:, :-1], dati.iloc[:, -1], \n",
    "                                                  test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Analisi esplorativa <a id=esplorativa> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati.iloc[:, :-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.replace(NUMERO_CLASSE).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.grafici import grafico_immagine_satellitare\n",
    "\n",
    "print(inspect.getsource(grafico_immagine_satellitare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "grafico_immagine_satellitare(X_train, y_train)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.grafici import diagrammi_scatola_baffi_pixel\n",
    "\n",
    "print(inspect.getsource(diagrammi_scatola_baffi_pixel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "diagrammi_scatola_baffi_pixel(X_train, y_train, 4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.grafici import diagrammi_scatola_baffi_classi\n",
    "\n",
    "print(inspect.getsource(diagrammi_scatola_baffi_classi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "1. Stimare le prime due componenti ICA di `X_train` e assegnarle alla variabile `X_ica`;\n",
    "2. Utilizzare la funzione `diagrammi_scatola_baffi_classi` per fare i diagrammi a scatola e baffi delle classi sia per la prima che per la seconda componente ICA.\n",
    "\n",
    "> Nota: `x=y_train` e `y=X_ica[:, 0]` per la prima componente (pensare a cosa si vuole vedere sull'asse x del grafico)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PCA, ICA e t-SNE a confronto <a id=confronto> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "ica = FastICA(n_components=2, whiten=True)\n",
    "pca = PCA(n_components=2, whiten=True)\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "X_ica = ica.fit_transform(X_train)\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "X_tsne  = tsne.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.grafici import grafico_componenti\n",
    "\n",
    "print(inspect.getsource(grafico_componenti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.title(\"PCA\")\n",
    "grafico_componenti(X_pca, y_train)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title(\"ICA\")\n",
    "grafico_componenti(X_ica, y_train)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title(\"t-SNE\")\n",
    "grafico_componenti(X_tsne, y_train)\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Commentare i risultati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ridurre la dimensionalità come parte di una pipeline di classificazione <a id=pipeline> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Creare una baseline <a id=baseline> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import  accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dc.fit(X_train, y_train)\n",
    "y_pred = dc.predict(X_val)\n",
    "\n",
    "dc_acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(\"Accuratezza DummyClassifier(strategy=\\\"most_frequent\\\"): {:.1f}%\".format(100 * dc_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinom = LogisticRegression(penalty=\"l2\", multi_class=\"multinomial\", C=float(\"inf\"), solver=\"newton-cg\")\n",
    "\n",
    "multinom.fit(X_train, y_train)\n",
    "y_pred = multinom.predict(X_val)\n",
    "\n",
    "multinom_acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(\"Accuratezza DummyClassifier(strategy=\\\"most_frequent\\\"): {:.1f}%\".format(100 * dc_acc))\n",
    "print(\"Accuratezza LogisticRegression(multi_class=\\\"multinomial\\\"): {:.1f}%\".format(100 * multinom_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Scegliere in numero di componenti principali <a id=scegliere_principali> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scegliere in numero di componenti principali studiando la varianza spiegata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(whiten=True)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from msbd.grafici import grafico_varianza_spiegata\n",
    "\n",
    "print(inspect.getsource(grafico_varianza_spiegata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "plt.subplot(121)\n",
    "grafico_varianza_spiegata(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.subplot(122)\n",
    "grafico_varianza_spiegata(pca.explained_variance_ratio_, cumulata=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = 3\n",
    "\n",
    "multinom = Pipeline([\n",
    "    (\"pca\", PCA(n_components=N_COMPONENTS, whiten=True)),\n",
    "    (\"multinom\", LogisticRegression(penalty=\"l2\", multi_class=\"multinomial\", C=float(\"inf\"), solver=\"newton-cg\")),\n",
    "])\n",
    "\n",
    "multinom.fit(X_train, y_train)\n",
    "y_pred = multinom.predict(X_val)\n",
    "\n",
    "print(\"Accuratezza DummyClassifier(strategy=\\\"most_frequent\\\"): {:.1f}%\".format(100 * dc_acc))\n",
    "print(\"Accuratezza LogisticRegression(multi_class=\\\"multinomial\\\"): {:.1f}%\".format(100 * multinom_acc))\n",
    "print(\"Accuratezza PCA(n_components={}) + LogisticRegression(multi_class=\\\"multinomial\\\"): {:.1f}%\".format(N_COMPONENTS, 100 * accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scegliere il numero di componenti principali in base all'errore sull'insieme di validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinom = Pipeline([\n",
    "    (\"pca\", PCA(whiten=True)),\n",
    "    (\"multinom\", LogisticRegression(penalty=\"l2\", multi_class=\"multinomial\", C=float(\"inf\"), solver=\"newton-cg\")),\n",
    "])\n",
    "\n",
    "acc = []\n",
    "\n",
    "for n_components in range(1, 26):\n",
    "    multinom.set_params(pca__n_components=n_components)\n",
    "    multinom.fit(X_train, y_train)\n",
    "    y_pred = multinom.predict(X_val)\n",
    "    acc.append(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "plt.title(\"Accuratezza al variare del numero di componenti principali\")\n",
    "plt.plot(range(1, len(acc) + 1), acc, marker='o', ls='--')\n",
    "plt.plot(np.argmax(acc) + 1, acc[np.argmax(acc)], c=\"tab:red\", marker=\"o\", \n",
    "         label=\"Miglior numero di componenti ({})\".format(np.argmax(acc) + 1))\n",
    "plt.xticks(range(1, len(acc) + 1), range(1, len(acc) + 1))\n",
    "plt.xlabel(\"Numero componenti principali\")\n",
    "plt.ylabel(\"Accuratezza\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Cambiare il `random_state` in `train_test_split` (nella cella dove abbiamo diviso i dati in `train` e `val`) e rieseguire le celle fino al grafico sopra. Il numero di componenti migliore è lo stesso? Commentare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nota: in questo caso sarebbe stato meglio utilizzare la convalida incrociata, in modo da ottenere stime più precise e i relativi errori standard. Una volta imparata la teoria relativa, in futuro considerare l'utilizzo della funzione di scikit-learn [validation_curve](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html#sklearn.model_selection.validation_curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = np.argmax(acc) + 1\n",
    "\n",
    "multinom = Pipeline([\n",
    "    (\"pca\", PCA(n_components=N_COMPONENTS, whiten=True)),\n",
    "    (\"multinom\", LogisticRegression(penalty=\"l2\", multi_class=\"multinomial\", C=float(\"inf\"), solver=\"newton-cg\")),\n",
    "])\n",
    "\n",
    "multinom.fit(X_train, y_train)\n",
    "y_pred = multinom.predict(X_val)\n",
    "\n",
    "print(\"Accuratezza DummyClassifier(strategy=\\\"most_frequent\\\"): {:.1f}%\".format(100 * dc_acc))\n",
    "print(\"Accuratezza LogisticRegression(multi_class=\\\"multinomial\\\"): {:.1f}%\".format(100 * multinom_acc))\n",
    "print(\"Accuratezza PCA(n_components={}) + LogisticRegression(multi_class=\\\"multinomial\\\"): {:.1f}%\".format(N_COMPONENTS, 100 * accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.grafici import grafico_matrice_confusione\n",
    "\n",
    "print(inspect.getsource(grafico_matrice_confusione))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "grafico_matrice_confusione(y_val, y_pred, CLASSI)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Si potrebbe calcolare l'accuratezza a partire dalla matrice di confusione? Se si, come?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Scegliere in numero di componenti indipendenti <a id=scegliere_indipendenti> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Ripetere quando visto per PCA utilizzando ICA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
