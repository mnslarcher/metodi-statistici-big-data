{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dati utilizzati in questo notebook sono stati presi dalla competizione di Kaggle [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic).\n",
    "\n",
    "### Riferimenti bibliografici:\n",
    "\n",
    "* Hastie, T.; Tibshirani, R. & Friedman, J. (2009), [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alberi di decisione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Titanic: Machine Learning from Disaster](#titanic)<br>\n",
    "    1.1 [Descrizione](#descrizione)<br>\n",
    "    1.2 [Leggere i dati e dividere le variabili esplicative dalla variabile risposta](#leggere_dati)<br>\n",
    "2. [Analisi esplorativa](#analisi_esplorativa)<br>\n",
    "    2.1 [Studiare le variabili esplicative](#esplicative)<br>\n",
    "    2.2 [Studiare la relazione tra variabili esplicative e variabile risposta](#esplicative_risposta)<br>\n",
    "3. [Alberi di decisione](#alberi)<br>\n",
    "    3.1 [Misure di impurità](#impurità)<br>\n",
    "    3.2 [Creare una o più baseline](#baseline)<br>\n",
    "4. [Scegliere gli iperparametri ottimali](#iperparametri)<br>\n",
    "    4.1 [Definire la griglia di ricerca (*grid search*)](#grid)<br>\n",
    "    4.2 [Calcolare l'accuratezza del modello per ogni combinazione degli iperparametri](#risultati)<br>\n",
    "    4.3 [Visualizzare i risultati della ricerca](#visualizzare_risultati)<br>\n",
    "    4.4 [Confrontare l'accuratezza del modello prima e dopo la scelta degli iperparametri ottimali](#confrontare)<br>\n",
    "5. [Visualizzare le caratteristiche dell'albero](#visualizzare)<br>\n",
    "    5.1 [Visualizzare l'albero](#visualizzare_albero)<br>\n",
    "    5.2 [Visualizzare l'importanza delle variabili](#visualizzare_importanza)<br>\n",
    "    5.3 [Visualizzare le superfici di decisione](#visualizzare_superfici)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) <a id=titanic> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Descrizione <a id=descrizione> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competition Description\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
    "\n",
    "### Goal\n",
    "It is your job to predict if a passenger survived the sinking of the Titanic or not. \n",
    "For each in the test set, you must predict a 0 or 1 value for the variable.\n",
    "\n",
    "### Metric\n",
    "Your score is the percentage of passengers you correctly predict. This is known simply as \"accuracy”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Leggere i dati e dividere le variabili esplicative dalla variabile risposta <a id=leggere_dati> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leggere i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"datasets/titanic\"\n",
    "\n",
    "dati = pd.read_csv(PATH + \"/train.csv\")\n",
    "print(\"Dimensione del dataset: {} x {}\".format(*dati.shape))\n",
    "dati.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividere le variabili esplicative dalla variabile risposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risposta =  \"Survived\"\n",
    "\n",
    "X, y = dati.drop(columns=risposta).copy(), dati[risposta].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Analisi esplorativa <a id=analisi_esplorativa> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Studiare le variabili esplicative <a id=esplicative> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: vedi esercizio seguente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Studiare la relazione tra variabili esplicative e variabile risposta <a id=esplicative_risposta> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividiere i dati in training e validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "dati_grafico = X_train[[\"Age\", \"Fare\"]].copy()\n",
    "dati_grafico['Survived'] = y_train.values\n",
    "dati_grafico.dropna(inplace=True)\n",
    "\n",
    "g = sns.JointGrid(\"Age\", \"Fare\", dati_grafico, ratio=2, height=6, space=0.2, ylim=[-10, 300])\n",
    "\n",
    "for i, gr in dati_grafico.groupby(\"Survived\"):\n",
    "    sns.distplot(gr[\"Age\"], ax=g.ax_marg_x)\n",
    "    sns.distplot(gr[\"Fare\"], ax=g.ax_marg_y, vertical=True)\n",
    "    g.ax_joint.plot(gr[\"Age\"], gr[\"Fare\"], 'o', alpha=0.5)\n",
    "plt.legend([\"Morto\", \"Soprav\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Cosa si può dedurre dal grafico precedente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: vedi esercizio seguente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "1. Completare l'analisi esplorativa commentandone i risultati;\n",
    "2. Creare almeno una variabile utilizzando le variabili \"Name\" e/o \"Ticket\" e/o \"Cabin\" sulla base dei risultati ottenuti al punto procedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminare le variabili che non si intendono utilizzare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nota: non avendo fatto l'analisi esplorativa, eliminiamo le variabili che richiederebbero un trattamento più lungo e una comprensione maggiore del data set. La riga seguente, come parti sucessive del notebook, vanno modificate a seconda delle variabili che si intende costruire sulla base dei risultati dell'analisi esplorativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "X_train = X_train.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "X_val = X_val.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "print(\"Variabili rimaste: {}.\".format(\", \".join(X.columns.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Alberi di decisione <a id=alberi> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Misure di impurità <a id=impurità> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Completare le funzioni `indice_gini` e `tasso_errata_classificazione` definite in `msbd/indici/indici.py`;\n",
    "\n",
    "Si ricorda che:\n",
    "\n",
    "$\n",
    "I_G(p) = 2 p (1 - p)\\\\\n",
    "I_{EC}(p) = 1 - \\max(p, 1 - p)\n",
    "$\n",
    "\n",
    "per $p \\in [0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.indici import indice_gini\n",
    "from msbd.indici import tasso_errata_classificazione\n",
    "\n",
    "print(inspect.getsource(indice_gini))\n",
    "print(inspect.getsource(tasso_errata_classificazione))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    p = np.linspace(0, 1, 1000)\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "\n",
    "    plt.title(\"Misure di impurità\")\n",
    "    plt.plot(p, indice_gini(p), label=\"Indice di impurità di Gini\")\n",
    "    plt.plot(p, tasso_errata_classificazione(p), label=\"Tasso di errata classificazione\")\n",
    "    plt.xlabel(\"p\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "except:\n",
    "    plt.close()\n",
    "    print(\"Le funzioni indice_gini() e tasso_errata_classificazione() non sono implementate correttamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Dato un nodo $n_{00} = [\\#\\,\\text{Morti}, \\#\\,\\text{Sopravvissuti}] = [400, 400]$, calcolare l'indice di impurità di Gini e il tasso di errata classificazione per:\n",
    "1. risultato della divisione $a$: $n^a_{10} = [300, 100]$ e $n^a_{11} = [100, 300]$;\n",
    "2. Il risultato della divisione $b$: $n^b_{10} = [200, 400]$ e $n^b_{11} = [200, 0]$:\n",
    "\n",
    "> Suggerimento: l'indice della divisione $a$ va calcolato come $I(a) = w^a_0 * I(n^a_{10}) + w^a_1 * I(n^a_{11})$ dove $w^a_0 = \\frac{\\sum n^a_{10}}{\\sum n^a_{10} + \\sum n^a_{11}}$ e $w^a_1 = \\frac{\\sum n^a_{11}}{\\sum n^a_{10} + \\sum n^a_{11}} = 1 - w^a_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n00 = np.array([400, 400])\n",
    "\n",
    "n10_a = np.array([300, 100])\n",
    "n11_a = np.array([100, 300])\n",
    "\n",
    "n10_b = np.array([200, 400])\n",
    "n11_b = np.array([200, 0])\n",
    "\n",
    "try:\n",
    "    # calcolare I_G(p) e I_EC(p) di n00, p = n00[1] / (n00[0] + n00[1])\n",
    "    ig_n00 = indice_gini(n00[1] / n00.sum())\n",
    "    ec_n00 = tasso_errata_classificazione(n00[1] / n00.sum())\n",
    "except:\n",
    "    ig_n00 = 0\n",
    "    ec_n00 = 0\n",
    "    print(\"Le funzioni indice_gini() e tasso_errata_classificazione() non sono implementate correttamente.\\n\")\n",
    "\n",
    "# TODO: sostituire gli 0. con i valori corretti\n",
    "# ============== YOUR CODE HERE ==============\n",
    "ec_n10_a = 0.\n",
    "ig_n11_a = 0.\n",
    "\n",
    "ec_n10_b = 0.\n",
    "ig_n11_b = 0.\n",
    "\n",
    "ig_a = 0.\n",
    "ec_a = 0.\n",
    "\n",
    "ig_b = 0.\n",
    "ec_b = 0.\n",
    "# ============================================\n",
    "\n",
    "print(\"Indice di impurità di Gini {}: {:.3f}\".format(n00, ig_n00))\n",
    "print(\"Tasso di errata classificazione {}: {:.3f}\\n\".format(n00, ig_n00))\n",
    "\n",
    "print(\"Indice di impurità di Gini {} -> {} e {}: {:.3f}\".format(n00, n10_a, n11_a, ig_a))\n",
    "print(\"Tasso di errata classificazione {} -> {} e {}: {:.3f}\\n\".format(n00, n10_a, n11_a, ec_a))\n",
    "\n",
    "print(\"Indice di impurità di Gini {} -> {} e {}: {:.3f}\".format(n00, n10_b, n11_b, ig_b))\n",
    "print(\"Tasso di errata classificazione {} -> {} e {}: {:.3f}\\n\".format(n00, n10_b, n11_b, ec_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Creare una o più baseline <a id=baseline> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DummyClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dc = DummyClassifier(\"most_frequent\")\n",
    "\n",
    "dc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dc.predict(X_val)\n",
    "dc_acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Accuratezza DummyClassifier(\"most_frequent\"): {:.1f}%'.format(100 * dc_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DecisionTreeClassifier` (senza ottimizzazione degli iperparametri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.preprocessamento import OttenereDummy\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = Pipeline([\n",
    "    (\"ottenere_dummy\", OttenereDummy(drop_first=True)),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), \n",
    "    (\"tree\", DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtc.predict(X_val)\n",
    "dtc_acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Accuratezza DummyClassifier(\"most_frequent\"): {:.1f}%'.format(100 * dc_acc))\n",
    "print(\"Accuratezza DecisionTreeClassifier(): {:.1f}%\".format(100 * dtc_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Calcolare l'accuratezza sull'insieme di *training*. Ci sono segnali di sovradattamento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scegliere gli iperparametri ottimali <a id=iperparametri> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Definire la griglia di ricerca (*grid search*) <a id=grid> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Profondità dell'albero allenato senza restrizioni: {}\".format(dtc.named_steps[\"tree\"].tree_.max_depth))\n",
    "print(\"Massimo numero minimo di osservazioni in una foglia: {}\".format(len(X_train) // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParameterGrid({\n",
    "    'tree__max_depth': np.arange(1, 18),\n",
    "    'tree__min_samples_leaf': 2 ** np.arange(9),\n",
    "})\n",
    "print(param_grid.param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nota: la ricerca degli iperparametri ottimali tramite *grid search* è fattibile solo quando questi sono pochi. Nel caso in cui gli iperparameteri siano molti, un'approccio migliore è  la *random search*. L'equivalente di [ParameterGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html) per la *random search* è [ParameterSampler](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterSampler.html).\n",
    "\n",
    "![search](figures/search.png)\n",
    "\n",
    "*Immagine presa da* [Random Search for Hyper-Parameter Optimization](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Immaginirare di dover trovare i valori ottimali di 10 iperparameteri differenti. Per ogniuno di essi vogliamo scegliere tra 5 possibili valori. Calcolare quante combinazioni si devono valutare (e quindi quante volte si deve allenare il modello) con il metodo *grid search* e con il metodo *random search*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Calcolare l'accuratezza del modello per ogni combinazione degli iperparametri <a id=risultati> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risultati = []\n",
    "\n",
    "for params in tqdm.tqdm(param_grid):\n",
    "    dtc.set_params(**params)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred = dtc.predict(X_val)\n",
    "    params[\"accuracy_score\"] = accuracy_score(y_val, y_pred)\n",
    "    risultati.append(params)\n",
    "\n",
    "risultati = pd.DataFrame(risultati).sort_values([\"accuracy_score\", \"tree__max_depth\"], ascending=[False, True])\n",
    "risultati.reset_index(drop=True, inplace=True)\n",
    "print(\"Primi 5:\")\n",
    "display(risultati.head())\n",
    "\n",
    "print(\"Ultimi 5:\")\n",
    "risultati.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Visualizzare i risultati della ricerca <a id=visualizzare_risultati> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.grafici import grafico_metrica_iperparametro\n",
    "\n",
    "print(inspect.getsource(grafico_metrica_iperparametro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "grafico_metrica_iperparametro(risultati, \"tree__max_depth\", \"accuracy_score\", alpha=0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "grafico_metrica_iperparametro(risultati, \"tree__min_samples_leaf\", \"accuracy_score\", alpha=0.5)\n",
    "plt.xscale(\"log\", basex=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.grafici import grafico_metrica_iperparametri\n",
    "\n",
    "print(inspect.getsource(grafico_metrica_iperparametri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "grafico_metrica_iperparametri(risultati, \"tree__max_depth\", \"tree__min_samples_leaf\", \"accuracy_score\")\n",
    "plt.yscale(\"log\", basey=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Confrontare l'accuratezza del modello prima e dopo la scelta degli iperparametri ottimali <a id=confrontare> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = risultati.loc[0, \"tree__max_depth\"]\n",
    "min_samples_leaf = risultati.loc[0, \"tree__min_samples_leaf\"]\n",
    "\n",
    "dtc_tun = Pipeline([\n",
    "    (\"ottenere_dummy\", OttenereDummy(drop_first=True)),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), \n",
    "    (\"tree\", DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf))\n",
    "])\n",
    "\n",
    "dtc_tun.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtc_tun.predict(X_val)\n",
    "dtc_tun_acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Accuratezza DummyClassifier(\"most_frequent\"): {:.1f}%'.format(100 * dc_acc))\n",
    "print(\"Accuratezza DecisionTreeClassifier(): {:.1f}%\".format(100 * dtc_acc))\n",
    "print(\"Accuratezza DecisionTreeClassifier(max_depth={}, min_samples_leaf={}): {:.1f}%\".format(\n",
    "    max_depth, min_samples_leaf, 100 * dtc_tun_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualizzare le caratteristiche dell'albero <a id=visualizzare> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Visualizzare l'albero <a id=visualizzare_albero> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(\n",
    "    decision_tree=dtc_tun.named_steps[\"tree\"], \n",
    "    max_depth=4,\n",
    "    feature_names=dtc.named_steps[\"ottenere_dummy\"].columns_,\n",
    "    class_names=(\"Morto\", \"Soprav\"),\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    ")\n",
    "display(graphviz.Source(dot_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Visualizzare l'importanza delle variabili <a id=visualizzare_importanza> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.grafici import grafico_importanza_variabili\n",
    "\n",
    "print(inspect.getsource(grafico_importanza_variabili))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importanze = dtc_tun.named_steps[\"tree\"].feature_importances_\n",
    "variabili = dtc_tun.named_steps[\"ottenere_dummy\"].columns_\n",
    "\n",
    "grafico_importanza_variabili(importanze, variabili)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Visualizzare le superfici di decisione <a id=visualizzare_superfici> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Imitare, per le variabili per cui ha senso, i grafici presenti in [Plot the decision surface of a decision tree on the iris dataset](https://scikit-learn.org/stable/auto_examples/tree/plot_iris.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
