{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dati utilizzati in questo notebook sono stati presi dalla competizione di Analytics Vidhya [Practice Problem: Big Mart Sales III](https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/#data_dictionary).\n",
    "\n",
    "### Riferimenti bibliografici:\n",
    "\n",
    "* Azzalini, A. &  Scarpa B. (2012), [Data Analysis and Data Mining: An Introduction](https://global.oup.com/academic/product/data-analysis-and-data-mining-9780199767106?q=Data%20Mining&lang=en&cc=it).\n",
    "* Hastie, T.; Tibshirani, R. & Friedman, J. (2009), [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressione stepwise, Ridge e LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Alcune definizioni utili](#definizioni)<br />\n",
    "2. [Decidere la metrica di valutazione](#metrica)<br />\n",
    "3. [Creare una baseline](#baseline)<br />\n",
    "    3.1 [`DummyRegressor`](#dummy_regressor)<br />\n",
    "    3.2 [Regressione lineare](#regressione_lineare)<br />\n",
    "4. [Regressione stepwise](#stepwise)<br />\n",
    "5. [Ridge](#ridge)<br />\n",
    "    5.1 [Selezione dell'iperparametero `alpha`](#alpha_ridge)<br />\n",
    "    5.2 [Risultati dell'esperimento](#risultati_ridge)<br />\n",
    "6. [LASSO (Least Absolute Shrinkage and Selection Operator)](#lasso)<br />\n",
    "    6.1 [Selezione dell'iperparametero `alpha`](#alpha_lasso)<br />\n",
    "    6.2 [Risultati dell'esperimento](#risultati_lasso)<br />\n",
    "7. [Valutare le performance sull'insieme di test](#performance_test)<br />\n",
    "8. [Utilizzare il modello su dati nuovi](#dati_nuovi)<br />\n",
    "    8.1 [Utilizzare la pipeline di preprocessamento e lo stimatore già allenati](#allenati)<br />\n",
    "    8.2 [Riallenare la pipeline da zero e prevedere le vendite per i nuovi dati](#riallenare)<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nota: per la descrizione del problema e dei dati vedere il notebook 07_analisi_esplorativa_e_preprocessamento_dei_dati.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"output/07/\"\n",
    "\n",
    "X_train = pd.read_pickle(PATH + \"/X_train.pkl\")\n",
    "X_val = pd.read_pickle(PATH + \"/X_val.pkl\")\n",
    "X_test = pd.read_pickle(PATH + \"/X_test.pkl\")\n",
    "y_train = pd.read_pickle(PATH + \"/y_train.pkl\")\n",
    "y_val = pd.read_pickle(PATH + \"/y_val.pkl\")\n",
    "y_test = pd.read_pickle(PATH + \"/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Alcune definizioni utili <a id=definizioni> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sia $y_i$ l'osservazione i-esima della variabile risposta, $\\overline{y}$ la media degli $y_i$ e $\\hat{y}_i$ la stima di $y_i$ data dal modello, si definiscono le seguenti quantità:\n",
    "\n",
    "**Somma dei quadrati dei residui**:\n",
    "$$\n",
    "\\mathrm{RSS} = \\sum\\limits_{i=1}^n(y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "**Somma dei quadrati totale**:\n",
    "$$\n",
    "\\mathrm{TSS} = \\sum\\limits_{i=1}^n(y_i - \\overline{y}_i)^2\n",
    "$$\n",
    "\n",
    "**Coefficiente di determinazione**:\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\mathrm{RSS}}{\\mathrm{TSS}}\n",
    "$$\n",
    "\n",
    "**Errore quadratico medio / stima della varianza dei residui**:\n",
    "$$\n",
    "\\mathrm{MSE} = \\hat{\\sigma}^2 = \\frac{\\mathrm{RSS}}{n}\n",
    "$$\n",
    "\n",
    "**Radice dell'errore quadratico medio**:\n",
    "$$\n",
    "\\mathrm{RMSE} = \\sqrt{\\mathrm{MSE}}\n",
    "$$\n",
    "\n",
    "**Criterio d'informazione di Akaike**:\n",
    "$$\n",
    "\\mathrm{AIC} = 2k - 2\\ln(\\hat{L})\n",
    "$$\n",
    "\n",
    "**Vaolore massimo della log-verosimiglianza, caso errori i.i.d. $\\sim{\\mathcal{N}}(0,\\sigma^2)$**:\n",
    "$$\n",
    "\\ln{(\\hat{L})} = -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln({\\hat{\\sigma}}^2) - \\frac{1}{2{\\hat{\\sigma}}^2}\\mathrm{RSS}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decidere la metrica di valutazione <a id=metrica> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric\n",
    "​\n",
    "Your model performance will be evaluated on the basis of your prediction of the sales for the test data (test.csv), which contains similar data-points as train except for the sales to be predicted. Your submission needs to be in the format as shown in \"SampleSubmission.csv\".\n",
    "​\n",
    "We at our end, have the actual sales for the test dataset, against which your predictions will be evaluated. We will use the Root Mean Square Error value to judge your response.\n",
    "​\n",
    "$\n",
    "RMSE = \\sqrt{\\frac{\\sum_{i=1}^N(Predicted_i - Actual_i)^2}{N}}\n",
    "$\n",
    "​\n",
    "Where,\n",
    "$N$: total number of observations\n",
    "Predicted: the response entered by user\n",
    "Actual: actual values of sales\n",
    "​\n",
    "Also, note that the test data is further divided into Public (25%) and Private (75%) data. Your initial responses will be checked and scored on the Public data. But, the final rankings will be based on score on Private data set. Since this is a practice problem, we will keep declare winners after specific time intervals and refresh the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.metriche import radice_errore_quadratico_medio\n",
    "\n",
    "print(inspect.getsource(radice_errore_quadratico_medio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creare una baseline <a id=baseline> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 `DummyRegressor` <a id=dummy_regressor> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = DummyRegressor(strategy='mean')\n",
    "\n",
    "dr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 training: {:.4f}\".format(dr.score(X_train, y_train)))\n",
    "print(\"R2 validation: {:.4f}\".format(dr.score(X_val, y_val)))\n",
    "print(\"RMSE training: {:.4f}\".format(radice_errore_quadratico_medio(y_train, dr.predict(X_train))))\n",
    "print(\"RMSE validation: {:.4f}\".format(radice_errore_quadratico_medio(y_val, dr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "1. È possibile ottenere un [coefficiente di determinazione](https://it.wikipedia.org/wiki/Coefficiente_di_determinazione) $R^2$ negativo?\n",
    "2. Ci stupisce che l'$R^2$ sull'insieme di training sia esattamente zero per il DummyRegressor?\n",
    "3. Se si valuta uno stimatore sull'insieme di validation, è necessario utilizzare l'$\\bar{R}^2$ ($R^2$ corretto) al posto del $R^2$? \n",
    "\n",
    "Motivare le risposte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Regressione lineare <a id=regressione_lineare> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nota: per un'implementazione del modello lineare e un summary più vicini a quelli di R considerare la classe [`OLS()`](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html) di [`statsmodels`](https://www.statsmodels.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.grafici import grafico_coefficienti\n",
    "\n",
    "print(inspect.getsource(grafico_coefficienti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "print(\"Intercetta: {:.2f}\".format(lr.intercept_))\n",
    "grafico_coefficienti(lr.coef_, X_train.columns)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"R2 training: {:.4f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"R2 validation: {:.4f}\".format(lr.score(X_val, y_val)))\n",
    "print(\"RMSE training: {:.4f}\".format(radice_errore_quadratico_medio(y_train, lr.predict(X_train))))\n",
    "print(\"RMSE validation: {:.4f}\".format(radice_errore_quadratico_medio(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Regressione stepwise <a id=stepwise> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from msbd.selezione_variabili import Stepwise\n",
    "\n",
    "print(inspect.getsource(Stepwise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.metriche import criterio_informazione_akaike\n",
    "\n",
    "print(inspect.getsource(criterio_informazione_akaike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise = Stepwise(LinearRegression(), criterio_informazione_akaike, \"avanti\", verboso=True)\n",
    "\n",
    "stepwise.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "L'implementazione del metodo `_selezione_avanti()` della classe `Stepwise` è generico ma computazionalmente oneroso, ad ogni chiamata di `_passo_avanti()` viene riallenato il modello una volta per ogni variabile considerata in quel passo.\n",
    "\n",
    "1. Sia $n=49$ il numero di variabili a disposizione (come nel nostro caso). Al massimo quante volte viene allenato il modello?\n",
    "2. Sia sempre $n=49$. Quanti sono tutti i possibili sottoinsiemi di variabili?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "print(\"Intercetta: {:.2f}\".format(stepwise.stimatore_.intercept_))\n",
    "grafico_coefficienti(\n",
    "    stepwise.stimatore_.coef_,\n",
    "    stepwise.variabili_selezionate_\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"R2 training: {:.4f}\".format(stepwise.score(X_train, y_train)))\n",
    "print(\"R2 validation: {:.4f}\".format(stepwise.score(X_val, y_val)))\n",
    "print(\"RMSE training: {:.4f}\".format(radice_errore_quadratico_medio(y_train, stepwise.predict(X_train))))\n",
    "print(\"RMSE validation: {:.4f}\".format(radice_errore_quadratico_medio(y_val, stepwise.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "1. Completare i metodi `_passo_indietro()`, `_selezione_avanti()`, `_selezione_ibrida()`;\n",
    "2. Ripetere l'esercizio con `procedura=\"indietro\"`. Si ottiene lo stesso insieme di variabili che con `procedura=\"avanti\"`?\n",
    "3. Ripetere l'esercizio con `procedura=\"ibrida\"`. Si ottiene lo stesso insieme di variabili che con `procedura=\"avanti\"`?\n",
    "4. Nel caso della regressione lineare, come si potrebbe velocizzare la selezione quando `procedura=\"indietro\"`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Ridge <a id=ridge> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.esperimenti import esperimento_regolarizzazione\n",
    "\n",
    "print(inspect.getsource(esperimento_regolarizzazione))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Selezione dell'iperparametero `alpha` <a id=alpha_ridge> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha_list = [1e-2, 1e-1, 1e-0, 1e+1, 1e+2, 1e+3, 1e+4]\n",
    "\n",
    "esperimento = esperimento_regolarizzazione(Ridge(), alpha_list, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Risultati dell'esperimento <a id=risultati_ridge> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$ e $\\mathrm{RMSE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esperimento[[\"R2_Train\", \"R2_Val\", \"RMSE_Train\", \"RMSE_Val\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficienti stimati al variare di `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = esperimento[X_train.columns].plot(figsize=(15, 5), legend=None, title=\"Grafico dei coefficienti Ridge al variare di alpha\", use_index=False, lw=2)\n",
    "plt.xticks(range(len(alpha_list)), alpha_list)\n",
    "plt.legend(loc='center', bbox_to_anchor=(0.5, -0.5), ncol=4)\n",
    "plt.xlabel(\"Alpha\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. LASSO (Least Absolute Shrinkage and Selection Operator) <a id=lasso> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Selezione dell'iperparametero `alpha` <a id=alpha_lasso> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha_list = [1e-3, 1e-2, 1e-1, 1e-0, 1e+1, 1e+2, 1e+3]\n",
    "\n",
    "esperimento = esperimento_regolarizzazione(Lasso(), alpha_list, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Risultati dell'esperimento <a id=risultati_lasso> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$ e $\\mathrm{RMSE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esperimento[[\"R2_Train\", \"R2_Val\", \"RMSE_Train\", \"RMSE_Val\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficienti stimati al variare di `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = esperimento[X_train.columns].plot(figsize=(15, 5), legend=None, title=\"Grafico dei coefficienti Lasso al variare di alpha\", use_index=False, lw=2)\n",
    "plt.xticks(range(len(alpha_list)), alpha_list)\n",
    "plt.legend(loc='center', bbox_to_anchor=(0.5, -0.5), ncol=4)\n",
    "plt.xlabel(\"Alpha\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Valutare le performance sull'insieme di test <a id=performance_test> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Scegliere lo stimatore migliore (ed eventuali iperparametri) tra quelli analizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: sostituire DummyRegressor con lo stimatore scelto\n",
    "# ============== YOUR CODE HERE ==============\n",
    "stimatore = DummyRegressor()\n",
    "# ============== YOUR CODE HERE =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval = X_train.append(X_val)\n",
    "y_trainval = y_train.append(y_val)\n",
    "\n",
    "stimatore.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 training + validation: {:.4f}\".format(stimatore.score(X_trainval, y_trainval)))\n",
    "print(\"R2 test: {:.4f}\".format(stimatore.score(X_test, y_test)))\n",
    "print(\"RMSE training + validation: {:.4f}\".format(radice_errore_quadratico_medio(y_trainval, stimatore.predict(X_trainval))))\n",
    "print(\"RMSE test: {:.4f}\".format(radice_errore_quadratico_medio(y_test, stimatore.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Utilizzare il modello su dati nuovi <a id=dati_nuovi> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leggere i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"datasets/big_mart_sales\"\n",
    "\n",
    "X_new = pd.read_csv(PATH + \"/Test_u94Q5KV.csv\")\n",
    "print(\"Dimensione del dataset: {} x {}\".format(*X_new.shape))\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Utilizzare la pipeline di preprocessamento e lo stimatore già allenati <a id=allenati> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"output/07\"\n",
    "\n",
    "pipeline = joblib.load(PATH + \"/preproc.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.transform(X_new).head() # non stiamo salvando X_new dopo la trasformazione, serve solo come esempio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.steps.append((\"stimatore\", stimatore)) # appendo lo stimatore alla pipeline di preprocessamento\n",
    "pipeline.named_steps.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nota: `pipeline.predict()` applica in sequenza gli step di preprocessamento definiti nella pipeline preproc.joblib a `X_new` e sucessivamente applica il metodo `predict()` dello stimatore allenato sopra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Riallenare la pipeline da zero e prevedere le vendite per i nuovi dati <a id=riallenare> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"datasets/big_mart_sales\" # cambiare in base a dove si è salvato il dataset\n",
    "\n",
    "dati = pd.read_csv(PATH + \"/Train_UWu5bXk.csv\")\n",
    "print(\"Dimensione del dataset: {} x {}\".format(*dati.shape))\n",
    "display(dati.head())\n",
    "\n",
    "risposta = \"Item_Outlet_Sales\"\n",
    "esplicative = sorted(col for col in dati.columns if col != risposta)\n",
    "\n",
    "X, y = dati[esplicative].copy(), dati[risposta].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X, y) # riallenamento della pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "1. Aggiungere a X_new la colonna *Item_Outlet_Sales_Pred*;\n",
    "2. Ordinare il X_new in base a *Item_Outlet_Sales_Pred* in ordine discendente;\n",
    "3. Commentare le prime e le ultime 5 righe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
